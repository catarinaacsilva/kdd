{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric: pandas and numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# graphics\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs, make_circles, make_moons, make_circles\n",
    "X_blobs, y_blobs = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=None)\n",
    "X_moon,y_moon= make_moons(n_samples=1000, shuffle=True, noise=None, random_state=None)\n",
    "X_cir, y_cir= make_circles(n_samples=1000, shuffle=True, noise=None, random_state=None, factor=0.4)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "\n",
    "ax1.scatter(X_blobs[y_blobs==0,0],X_blobs[y_blobs==0,1],marker='s',color='r',label='0' )\n",
    "ax1.scatter(X_blobs[y_blobs==1,0],X_blobs[y_blobs==1,1],marker='s',color='g',label='0' )\n",
    "\n",
    "ax2.scatter(X_moon[y_moon==0,0],X_moon[y_moon==0,1],marker='s',color='r',label='0' )\n",
    "ax2.scatter(X_moon[y_moon==1,0],X_moon[y_moon==1,1],marker='s',color='g',label='0' )\n",
    "\n",
    "ax3.scatter(X_cir[y_cir==0,0],X_cir[y_cir==0,1],marker='s',color='r',label='0' )\n",
    "ax3.scatter(X_cir[y_cir==1,0],X_cir[y_cir==1,1],marker='s',color='g',label='0' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.3\n",
    "\n",
    "#X_train_blobs, X_test_blobs, y_train_blobs, y_test_blobs = train_test_split(X_blobs, y_blobs, test_size=test_size, random_state=0, stratify=y_blobs)\n",
    "#X_train_moon, X_test_moon, y_train_moon, y_test_moon = train_test_split(X_moon, y_moon, test_size=test_size, random_state=0, stratify=y_moon)\n",
    "#X_train_cir, X_test_cir, y_train_cir, y_test_cir = train_test_split(X_cir, y_cir, test_size=test_size, random_state=0, stratify=y_cir)\n",
    "\n",
    "d_blobs = train_test_split(X_blobs, y_blobs, test_size=test_size, random_state=0, stratify=y_blobs)\n",
    "d_moon = train_test_split(X_moon, y_moon, test_size=test_size, random_state=0, stratify=y_moon)\n",
    "d_cir = train_test_split(X_cir, y_cir, test_size=test_size, random_state=0, stratify=y_cir)\n",
    "\n",
    "datasets = [d_blobs, d_moon, d_cir]\n",
    "names = ['Blobs', 'Moon', 'Circle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "\n",
    "# Computes the confusion matrix for the McNemar test\n",
    "def create_McNemar_matrix(y_test, y_pred1, y_pred2):\n",
    "    a = b = c = d = 0\n",
    "    \n",
    "    for i in range(0, len(y_test)):\n",
    "        #print('[{}, {}, {}]'.format(y_test[i], y_pred1[i], y_pred2[i]))\n",
    "        if y_test[i] == y_pred1[i] and y_test[i] == y_pred2[i]:\n",
    "            a += 1\n",
    "        elif y_test[i] == y_pred1[i]:\n",
    "            b += 1\n",
    "        elif y_test[i] == y_pred2[i]:\n",
    "            c += 1\n",
    "        else:\n",
    "            d += 1\n",
    "    \n",
    "    return np.array([[a, b], [c, d]])\n",
    "\n",
    "\n",
    "# Compute both models accuracy based on the McNemar table\n",
    "def model_acc_McNemar(matrix):\n",
    "    n = matrix.sum()\n",
    "    acc1 = (matrix[0, 0] + matrix[0, 1]) / n\n",
    "    acc2 = (matrix[0, 0] + matrix[1, 0]) / n\n",
    "    return (acc1, acc2)\n",
    "\n",
    "\n",
    "# Computes the \n",
    "def McNemar_test(matrix):\n",
    "    b = matrix[0, 1]\n",
    "    c = matrix[1, 0]\n",
    "    n = b + c\n",
    "    \n",
    "    if n > 0:\n",
    "        chi2 = ((math.fabs(b-c)-1.0)**2) / (b+c)\n",
    "    else:\n",
    "        chi2 = ((math.fabs(b-c)-1.0)**2)\n",
    "    \n",
    "    p = min(scipy.stats.binom.cdf(min(b, c), n, 0.5) * 2.0, 1.)\n",
    "    \n",
    "    return (chi2, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# significance threshold\n",
    "a = 0.05\n",
    "\n",
    "# Create a perceptron and assign hyperparameters (max_iter, eta0- learning rate)\n",
    "ppn = Perceptron(penalty=None, alpha=0.0001, fit_intercept=True, tol=None, \n",
    "                 eta0=0.1, n_jobs=1, random_state=0, class_weight=None, warm_start=False)\n",
    "# Create a MLP and assign hyperparameters (max_iter, eta0- learning rate)\n",
    "mlp = MLPClassifier(alpha=0.0001, random_state=0, max_iter=1000)\n",
    "\n",
    "# Create a linear SVM\n",
    "svm_linear = SVC(kernel='linear')\n",
    "\n",
    "# Create a RBF SVM\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "models = [(svm_linear, svm_rbf), (ppn, mlp)]\n",
    "names_models = [('SVM(Linear)', 'SVM(RBF)'), ('Perceptron', 'Multilayer Neural Network')]\n",
    "\n",
    "for i in range(0, len(datasets)):\n",
    "    (X_train, X_test, y_train, y_test) = datasets[i]\n",
    "    print('Dataset: {}'.format(names[i]))\n",
    "    Xs = scaler.fit_transform(X_train)\n",
    "    Xtest = scaler.transform(X_test)\n",
    "    \n",
    "    for j in range(0, len(models)):\n",
    "        model1, model2 = models[j]\n",
    "        print('Comparing Models {} & {}'.format(names_models[j][0], names_models[j][1]))\n",
    "            \n",
    "        # Model 1 Learning\n",
    "        model1.fit(Xs, y_train)\n",
    "        y_pred_1 = model1.predict(Xtest)\n",
    "        \n",
    "        # Model 2 Learning\n",
    "        model2.fit(Xs, y_train)\n",
    "        y_pred_2 = model2.predict(Xtest)\n",
    "    \n",
    "        m = create_McNemar_matrix(y_test, y_pred_1, y_pred_2)\n",
    "        print(m)\n",
    "        m1_acc, m2_acc = model_acc_McNemar(m)\n",
    "        print('Model 1 = {}; Model 2 = {}'.format(m1_acc, m2_acc))\n",
    "        chi2, p = McNemar_test(m)\n",
    "    \n",
    "        if(p > a):\n",
    "            print('There is no statistical different between the models')\n",
    "        else:\n",
    "            if m1_acc > m2_acc:\n",
    "                print('Model 1 is better thant Model 2 ({})'.format(m1_acc))\n",
    "            else:\n",
    "                print('Model 2 is better thant Model 1 ({})'.format(m2_acc))\n",
    "        print('*********************************')\n",
    "    print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
